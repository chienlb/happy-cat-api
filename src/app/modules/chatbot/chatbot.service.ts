import { Injectable, Logger, NotFoundException, BadRequestException } from '@nestjs/common';
import { InjectModel } from '@nestjs/mongoose';
import { Model, Types } from 'mongoose';
import { GoogleGenerativeAI } from '@google/generative-ai';
import { ConfigService } from '@nestjs/config';
import { Conversation, ConversationDocument } from './schema/conversation.schema';
import { ChatDto } from './dto/chat.dto';
import { CreateConversationDto } from './dto/create-conversation.dto';

@Injectable()
export class ChatbotService {
  private readonly logger = new Logger(ChatbotService.name);
  private genAI: GoogleGenerativeAI;
  private model: any;
  private readonly systemInstruction = `
Báº¡n lÃ  Happy Cat - trá»£ lÃ½ AI thÃ´ng minh vÃ  thÃ¢n thiá»‡n trÃªn ná»n táº£ng há»c tiáº¿ng Anh dÃ nh cho há»c sinh tiá»ƒu há»c (6-11 tuá»•i).

## Vá»€ Ná»€N Táº¢NG HAPPY CAT:
- Ná»n táº£ng há»c tiáº¿ng Anh trá»±c tuyáº¿n toÃ n diá»‡n cho há»c sinh tiá»ƒu há»c
- Cung cáº¥p cÃ¡c khÃ³a há»c tá»« cÆ¡ báº£n Ä‘áº¿n nÃ¢ng cao phÃ¹ há»£p vá»›i tá»«ng lá»©a tuá»•i
- CÃ³ cÃ¡c bÃ i há»c tÆ°Æ¡ng tÃ¡c, trÃ² chÆ¡i, bÃ i táº­p phÃ¡t Ã¢m, vÃ  hoáº¡t Ä‘á»™ng thá»±c hÃ nh
- Há»‡ thá»‘ng badges (huy hiá»‡u) vÃ  Ä‘iá»ƒm thÆ°á»Ÿng Ä‘á»ƒ Ä‘á»™ng viÃªn há»c sinh
- TÃ­nh nÄƒng thi Ä‘ua, báº£ng xáº¿p háº¡ng Ä‘á»ƒ táº¡o Ä‘á»™ng lá»±c há»c táº­p
- CÃ³ pháº§n dÃ nh cho phá»¥ huynh theo dÃµi tiáº¿n Ä‘á»™ há»c cá»§a con

## VAI TRÃ’ Cá»¦A Báº N:
1. **Trá»£ lÃ½ há»c táº­p**: GiÃºp há»c sinh hiá»ƒu bÃ i, giáº£i Ä‘Ã¡p tháº¯c máº¯c vá» ngá»¯ phÃ¡p, tá»« vá»±ng
2. **NgÆ°á»i báº¡n thÃ¢n thiá»‡n**: TrÃ² chuyá»‡n báº±ng ngÃ´n ngá»¯ Ä‘Æ¡n giáº£n, vui váº», phÃ¹ há»£p vá»›i tráº» em
3. **Äá»™ng viÃªn khÃ­ch lá»‡**: LuÃ´n khen ngá»£i, Ä‘á»™ng viÃªn khi há»c sinh lÃ m tá»‘t
4. **HÆ°á»›ng dáº«n viÃªn**: GiÃºp há»c sinh Ä‘iá»u hÆ°á»›ng sá»­ dá»¥ng cÃ¡c tÃ­nh nÄƒng trÃªn website

## Ná»˜I DUNG Há»ŒC TIáº¾NG ANH TIá»‚U Há»ŒC:
**Tá»« vá»±ng theo chá»§ Ä‘á»**:
- Gia Ä‘Ã¬nh vÃ  báº¡n bÃ¨ (family, friends)
- Sá»‘ Ä‘áº¿m vÃ  mÃ u sáº¯c (numbers 1-100, colors)
- Äá»™ng váº­t (animals: dog, cat, elephant, v.v.)
- TrÆ°á»ng há»c (school: pen, book, teacher, classroom)
- Thá»©c Äƒn vÃ  Ä‘á»“ uá»‘ng (food & drinks: apple, rice, water)
- Äá»“ váº­t xung quanh (objects: toy, ball, chair, table)
- Thá»i tiáº¿t (weather: sunny, rainy, cloudy)
- Hoáº¡t Ä‘á»™ng hÃ ng ngÃ y (daily activities: eat, sleep, play)

**Ngá»¯ phÃ¡p cÆ¡ báº£n**:
- To be: I am, You are, He/She/It is
- This is / These are
- Have / Has
- Äá»™ng tá»« thÆ°á»ng á»Ÿ thÃ¬ hiá»‡n táº¡i Ä‘Æ¡n (I like, He likes)
- Can / Can't (I can swim, I can't fly)
- Giá»›i tá»«: in, on, under, next to
- Äáº¡i tá»« nhÃ¢n xÆ°ng: I, you, he, she, it, we, they

**Ká»¹ nÄƒng**:
- Nghe vÃ  nháº¯c láº¡i (listening & repeating)
- PhÃ¡t Ã¢m Ä‘Ãºng (pronunciation)
- Äá»c tá»« vÃ  cÃ¢u Ä‘Æ¡n giáº£n (reading)
- Viáº¿t chá»¯ cÃ¡i vÃ  tá»« (writing)
- Giao tiáº¿p cÆ¡ báº£n (basic conversation)

## CÃCH TRáº¢ Lá»œI:
1. **NgÃ´n ngá»¯ Ä‘Æ¡n giáº£n**: DÃ¹ng tá»« dá»… hiá»ƒu, cÃ¢u ngáº¯n gá»n
2. **Emoji vui nhá»™n**: ThÃªm emoji Ä‘á»ƒ táº¡o khÃ´ng khÃ­ vui váº» ğŸ˜Š ğŸ‰ â­
3. **VÃ­ dá»¥ cá»¥ thá»ƒ**: LuÃ´n Ä‘Æ°a vÃ­ dá»¥ dá»… hiá»ƒu khi giáº£i thÃ­ch
4. **KhÃ­ch lá»‡**: Khen ngá»£i vÃ  Ä‘á»™ng viÃªn: "Giá»i láº¯m!", "Tuyá»‡t vá»i!", "Cá»‘ lÃªn nÃ o!"
5. **TÆ°Æ¡ng tÃ¡c**: Äáº·t cÃ¢u há»i Ä‘á»ƒ há»c sinh tÆ° duy: "Em cÃ³ biáº¿t khÃ´ng?", "Em thá»­ xem?"
6. **An toÃ n**: KhÃ´ng bÃ n vá» chá»§ Ä‘á» khÃ´ng phÃ¹ há»£p vá»›i tráº» em

## KHI ÄÆ¯á»¢C Há»I Vá»€:
- **Tá»« vá»±ng**: Giáº£i thÃ­ch nghÄ©a, phÃ¡t Ã¢m, Ä‘Æ°a vÃ­ dá»¥ cÃ¢u
- **Ngá»¯ phÃ¡p**: Giáº£i thÃ­ch Ä‘Æ¡n giáº£n vá»›i vÃ­ dá»¥ minh há»a
- **CÃ¡ch há»c**: Gá»£i Ã½ phÆ°Æ¡ng phÃ¡p há»c phÃ¹ há»£p vá»›i lá»©a tuá»•i
- **TÃ­nh nÄƒng web**: HÆ°á»›ng dáº«n sá»­ dá»¥ng cÃ¡c chá»©c nÄƒng trÃªn Happy Cat
- **Äá»™ng lá»±c**: Äá»™ng viÃªn, chia sáº» máº¹o há»c táº­p hiá»‡u quáº£

HÃ£y luÃ´n nhá»›: Báº¡n lÃ  ngÆ°á»i báº¡n Ä‘Ã¡ng tin cáº­y giÃºp cÃ¡c em yÃªu thÃ­ch tiáº¿ng Anh! ğŸŒŸ
`;

  constructor(
    @InjectModel(Conversation.name)
    private conversationModel: Model<ConversationDocument>,
    private configService: ConfigService,
  ) {
    const apiKey = this.configService.get<string>('GEMINI_API_KEY');
    if (!apiKey) {
      throw new Error('GEMINI_API_KEY is not configured');
    }
    
    this.genAI = new GoogleGenerativeAI(apiKey);
    this.model = this.genAI.getGenerativeModel({ 
      model: 'gemini-pro',
      systemInstruction: this.systemInstruction,
    });
  }

  /**
   * Táº¡o cuá»™c trÃ² chuyá»‡n má»›i
   */
  async createConversation(
    userId: string,
    createConversationDto: CreateConversationDto,
  ): Promise<Conversation> {
    const conversation = new this.conversationModel({
      ...createConversationDto,
      userId: new Types.ObjectId(userId),
      messages: [],
    });

    await conversation.save();
    this.logger.log(`Created conversation ${conversation._id} for user ${userId}`);
    return conversation;
  }

  /**
   * Láº¥y táº¥t cáº£ cuá»™c trÃ² chuyá»‡n cá»§a user
   */
  async getConversations(userId: string): Promise<Conversation[]> {
    return this.conversationModel
      .find({ userId: new Types.ObjectId(userId), isActive: true })
      .sort({ updatedAt: -1 })
      .exec();
  }

  /**
   * Láº¥y chi tiáº¿t cuá»™c trÃ² chuyá»‡n
   */
  async getConversation(userId: string, conversationId: string): Promise<Conversation> {
    const conversation = await this.conversationModel.findOne({
      _id: conversationId,
      userId: new Types.ObjectId(userId),
    });

    if (!conversation) {
      throw new NotFoundException('Conversation not found');
    }

    return conversation;
  }

  /**
   * XÃ³a cuá»™c trÃ² chuyá»‡n (soft delete)
   */
  async deleteConversation(userId: string, conversationId: string): Promise<void> {
    const result = await this.conversationModel.updateOne(
      { _id: conversationId, userId: new Types.ObjectId(userId) },
      { isActive: false },
    );

    if (result.matchedCount === 0) {
      throw new NotFoundException('Conversation not found');
    }

    this.logger.log(`Deleted conversation ${conversationId} for user ${userId}`);
  }

  /**
   * Chat vá»›i Gemini AI
   */
  async chat(userId: string, chatDto: ChatDto): Promise<any> {
    try {
      let conversation: ConversationDocument | null = null;
      let history: any[] = [];

      // Náº¿u cÃ³ conversationId, load lá»‹ch sá»­ tá»« database
      if (chatDto.conversationId) {
        conversation = await this.conversationModel.findOne({
          _id: chatDto.conversationId,
          userId: new Types.ObjectId(userId),
        });

        if (!conversation) {
          throw new NotFoundException('Conversation not found');
        }

        // Chuyá»ƒn Ä‘á»•i lá»‹ch sá»­ tá»« database sang format cá»§a Gemini
        history = conversation.messages.map((msg) => ({
          role: msg.role,
          parts: [{ text: msg.parts }],
        }));
      } else if (chatDto.history && chatDto.history.length > 0) {
        // Náº¿u cÃ³ history tá»« client
        history = chatDto.history.map((msg) => ({
          role: msg.role,
          parts: [{ text: msg.parts }],
        }));
      }

      // Táº¡o chat session vá»›i lá»‹ch sá»­
      const chat = this.model.startChat({
        history: history,
        generationConfig: {
          maxOutputTokens: 1000,
          temperature: 0.7,
        },
      });

      // Gá»­i tin nháº¯n vÃ  nháº­n pháº£n há»“i
      const result = await chat.sendMessage(chatDto.message);
      const response = await result.response;
      const text = response.text();

      // LÆ°u tin nháº¯n vÃ o database náº¿u cÃ³ conversation
      if (conversation) {
        conversation.messages.push({
          role: 'user',
          parts: chatDto.message,
          timestamp: new Date(),
        });
        conversation.messages.push({
          role: 'model',
          parts: text,
          timestamp: new Date(),
        });
        await conversation.save();
      }

      this.logger.log(`Chat completed for user ${userId}`);

      return {
        message: text,
        conversationId: conversation?._id,
        timestamp: new Date(),
      };
    } catch (error) {
      this.logger.error(`Error in chat: ${error.message}`, error.stack);
      throw new BadRequestException('Failed to process chat request');
    }
  }

  /**
   * Chat stream (real-time response)
   */
  async *chatStream(userId: string, chatDto: ChatDto): AsyncGenerator<string> {
    try {
      let conversation: ConversationDocument | null = null;
      let history: any[] = [];

      if (chatDto.conversationId) {
        conversation = await this.conversationModel.findOne({
          _id: chatDto.conversationId,
          userId: new Types.ObjectId(userId),
        });

        if (!conversation) {
          throw new NotFoundException('Conversation not found');
        }

        history = conversation.messages.map((msg) => ({
          role: msg.role,
          parts: [{ text: msg.parts }],
        }));
      } else if (chatDto.history && chatDto.history.length > 0) {
        history = chatDto.history.map((msg) => ({
          role: msg.role,
          parts: [{ text: msg.parts }],
        }));
      }

      const chat = this.model.startChat({
        history: history,
        generationConfig: {
          maxOutputTokens: 1000,
          temperature: 0.7,
        },
      });

      const result = await chat.sendMessageStream(chatDto.message);
      let fullResponse = '';

      for await (const chunk of result.stream) {
        const chunkText = chunk.text();
        fullResponse += chunkText;
        yield chunkText;
      }

      // LÆ°u tin nháº¯n sau khi stream xong
      if (conversation) {
        conversation.messages.push({
          role: 'user',
          parts: chatDto.message,
          timestamp: new Date(),
        });
        conversation.messages.push({
          role: 'model',
          parts: fullResponse,
          timestamp: new Date(),
        });
        await conversation.save();
      }

      this.logger.log(`Chat stream completed for user ${userId}`);
    } catch (error) {
      this.logger.error(`Error in chat stream: ${error.message}`, error.stack);
      throw new BadRequestException('Failed to process chat stream request');
    }
  }
}
